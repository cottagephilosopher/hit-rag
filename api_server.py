"""
RAG æ–‡æ¡£é¢„å¤„ç† API æœåŠ¡
æä¾›æ–‡æ¡£åˆ—è¡¨ã€å¤„ç†çŠ¶æ€æŸ¥è¯¢å’Œå¤„ç†è§¦å‘æ¥å£
åŒæ—¶æä¾› chunk æ›´æ–°å’Œç‰ˆæœ¬å†å²æ¥å£
"""

import os
import json
import subprocess
from pathlib import Path
from typing import List, Dict, Any, Optional
from datetime import datetime
from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import uvicorn
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# å¯¼å…¥æ•°æ®åº“æ“ä½œæ¨¡å—
from database import (
    init_database,
    get_chunk,
    update_chunk,
    insert_log,
    get_chunk_logs,
    import_json_to_db,
    get_document_by_filename,
    get_tags_by_filename,
    add_tag_by_filename,
    remove_tag_by_filename,
    update_chunk_milvus_id,
    get_vectorizable_chunks,
    get_vectorization_stats,
    get_chunk_by_milvus_id,
    get_connection,
    get_all_tags_with_stats,
    delete_tag_from_all_chunks,
    rename_tag_in_all_chunks,
    merge_tags_in_all_chunks
)

# å¯¼å…¥å‘é‡åŒ–ç®¡ç†æ¨¡å—
from vector_db.vectorization_manager import VectorizationManager

app = FastAPI(title="RAG Preprocessor API")

# é…ç½®CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ==================== è·¯å¾„é…ç½® ====================
# ä»ç¯å¢ƒå˜é‡è¯»å–è·¯å¾„é…ç½®ï¼Œå¦‚æœæœªè®¾ç½®åˆ™ä½¿ç”¨é»˜è®¤å€¼

# åŸºç¡€ç›®å½•ï¼šé¡¹ç›®æ ¹ç›®å½•ï¼ˆé»˜è®¤ä¸ºå½“å‰æ–‡ä»¶çš„çˆ¶ç›®å½•çš„çˆ¶ç›®å½•ï¼‰
BASE_DIR = Path(os.getenv("BASE_DIR", Path(__file__).parent.parent))

# Markdown æ–‡æ¡£ç›®å½•ï¼šå­˜æ”¾æ‰€æœ‰å¾…å¤„ç†çš„ .md æ–‡ä»¶
# é»˜è®¤ä½ç½®ï¼š{BASE_DIR}/all-md
ALL_MD_DIR = Path(os.getenv("ALL_MD_DIR", BASE_DIR / "all-md"))

# è¾“å‡ºç›®å½•ï¼šå­˜æ”¾å¤„ç†åçš„ JSON æ–‡ä»¶
# é»˜è®¤ä½ç½®ï¼š{BASE_DIR}/rag-visualizer/public/output
OUTPUT_DIR = Path(os.getenv("OUTPUT_DIR", BASE_DIR / "hit-rag-ui" / "public" / "output"))

# é¡¹ç›®å·¥ä½œç›®å½•ï¼šå½“å‰é¡¹ç›®ç›®å½•ï¼ˆikn-plus/hit-ragï¼‰
# é»˜è®¤ä½ç½®ï¼šå½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•
IKN_PLUS_DIR = Path(os.getenv("IKN_PLUS_DIR", Path(__file__).parent))

# å­˜å‚¨å¤„ç†ä»»åŠ¡çŠ¶æ€
processing_tasks = {}

# åˆå§‹åŒ–å‘é‡åŒ–ç®¡ç†å™¨ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼Œé¿å…å¯åŠ¨å¤±è´¥ï¼‰
vectorization_manager = None

def get_vectorization_manager() -> VectorizationManager:
    """è·å–å‘é‡åŒ–ç®¡ç†å™¨ï¼ˆæ‡’åŠ è½½ï¼‰"""
    global vectorization_manager
    if vectorization_manager is None:
        try:
            vectorization_manager = VectorizationManager()
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"å‘é‡åŒ–æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {str(e)}")
    return vectorization_manager


class Document(BaseModel):
    filename: str
    status: str  # "processed" | "processing" | "not_processed" | "error"
    output_path: str | None = None
    processed_at: str | None = None
    error: str | None = None


class ProcessRequest(BaseModel):
    filename: str


class ChunkUpdateRequest(BaseModel):
    """Chunk æ›´æ–°è¯·æ±‚"""
    edited_content: Optional[str] = None
    status: Optional[int] = None
    content_tags: Optional[List[str]] = None
    user_tag: Optional[str] = None
    editor_id: Optional[str] = "unknown"


class ChunkLogEntry(BaseModel):
    """Chunk æ—¥å¿—æ¡ç›®"""
    id: int
    action: str
    message: Optional[str]
    created_at: str
    user_id: Optional[str]
    payload: Optional[Dict[str, Any]]


def get_output_path(filename: str) -> Path:
    """è·å–æ–‡æ¡£çš„è¾“å‡ºè·¯å¾„"""
    stem = Path(filename).stem
    return OUTPUT_DIR / f"{stem}_final_chunks.json"


def check_document_status(filename: str) -> Dict[str, Any]:
    """æ£€æŸ¥æ–‡æ¡£å¤„ç†çŠ¶æ€"""
    output_path = get_output_path(filename)

    # æ£€æŸ¥æ˜¯å¦åœ¨å¤„ç†ä¸­
    if filename in processing_tasks:
        task_status = processing_tasks[filename]
        if task_status["status"] == "processing":
            return {
                "filename": filename,
                "status": "processing",
                "output_path": None
            }
        elif task_status["status"] == "error":
            return {
                "filename": filename,
                "status": "error",
                "error": task_status.get("error"),
                "output_path": None
            }

    # æ£€æŸ¥æ˜¯å¦å·²å¤„ç†
    if output_path.exists():
        try:
            with open(output_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                processed_at = data.get("metadata", {}).get("processed_at")
            return {
                "filename": filename,
                "status": "processed",
                "output_path": f"./output/{output_path.name}",
                "processed_at": processed_at
            }
        except Exception as e:
            return {
                "filename": filename,
                "status": "error",
                "error": f"è¯»å–è¾“å‡ºæ–‡ä»¶å¤±è´¥: {str(e)}",
                "output_path": None
            }

    return {
        "filename": filename,
        "status": "not_processed",
        "output_path": None
    }


@app.get("/api/documents", response_model=List[Document])
async def list_documents():
    """åˆ—å‡ºæ‰€æœ‰æ–‡æ¡£åŠå…¶çŠ¶æ€"""
    if not ALL_MD_DIR.exists():
        raise HTTPException(status_code=500, detail=f"æ–‡æ¡£ç›®å½•ä¸å­˜åœ¨: {ALL_MD_DIR}")

    documents = []
    for file in sorted(ALL_MD_DIR.glob("*.md")):
        status_info = check_document_status(file.name)
        documents.append(Document(**status_info))

    return documents


@app.get("/api/documents/{filename}/status", response_model=Document)
async def get_document_status(filename: str):
    """è·å–å•ä¸ªæ–‡æ¡£çš„çŠ¶æ€"""
    md_path = ALL_MD_DIR / filename
    if not md_path.exists():
        raise HTTPException(status_code=404, detail=f"æ–‡æ¡£ä¸å­˜åœ¨: {filename}")

    status_info = check_document_status(filename)
    return Document(**status_info)


async def process_document_task(filename: str):
    """åå°ä»»åŠ¡ï¼šå¤„ç†æ–‡æ¡£"""
    md_path = ALL_MD_DIR / filename
    output_path = get_output_path(filename)

    # æ ‡è®°ä¸ºå¤„ç†ä¸­
    processing_tasks[filename] = {
        "status": "processing",
        "started_at": datetime.now().isoformat()
    }

    try:
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

        # æ„å»ºå‘½ä»¤
        cmd = [
            "uv", "run", "main.py",
            str(md_path.resolve()),
            "-o", str(OUTPUT_DIR.resolve())
        ]

        # æ‰§è¡Œå¤„ç†
        result = subprocess.run(
            cmd,
            cwd=IKN_PLUS_DIR,
            capture_output=True,
            text=True,
            timeout=600  # 10åˆ†é’Ÿè¶…æ—¶
        )

        if result.returncode == 0:
            processing_tasks[filename] = {
                "status": "completed",
                "completed_at": datetime.now().isoformat(),
                "output_path": str(output_path)
            }

            # å¯¼å…¥åˆ°æ•°æ®åº“
            try:
                import_json_to_db(output_path, filename)
            except Exception as e:
                print(f"Warning: Failed to import to DB: {e}")
        else:
            error_msg = result.stderr or result.stdout or "Unknown error"
            processing_tasks[filename] = {
                "status": "error",
                "error": error_msg,
                "completed_at": datetime.now().isoformat()
            }

    except subprocess.TimeoutExpired:
        processing_tasks[filename] = {
            "status": "error",
            "error": "å¤„ç†è¶…æ—¶ï¼ˆè¶…è¿‡10åˆ†é’Ÿï¼‰",
            "completed_at": datetime.now().isoformat()
        }

    except Exception as e:
        processing_tasks[filename] = {
            "status": "error",
            "error": str(e),
            "completed_at": datetime.now().isoformat()
        }


@app.post("/api/documents/{filename}/process", response_model=Document)
async def process_document(filename: str, background_tasks: BackgroundTasks):
    """è§¦å‘æ–‡æ¡£å¤„ç†"""
    md_path = ALL_MD_DIR / filename
    if not md_path.exists():
        raise HTTPException(status_code=404, detail=f"æ–‡æ¡£ä¸å­˜åœ¨: {filename}")

    # æ£€æŸ¥æ˜¯å¦å·²åœ¨å¤„ç†ä¸­
    status_info = check_document_status(filename)
    if status_info["status"] == "processing":
        return Document(**status_info)

    # æ·»åŠ åå°ä»»åŠ¡
    background_tasks.add_task(process_document_task, filename)

    return Document(
        filename=filename,
        status="processing",
        output_path=None
    )


@app.delete("/api/documents/{filename}/output")
async def delete_output(filename: str):
    """åˆ é™¤æ–‡æ¡£çš„è¾“å‡ºç»“æœï¼ˆç”¨äºé‡æ–°å¤„ç†ï¼‰"""
    output_path = get_output_path(filename)

    if output_path.exists():
        output_path.unlink()
        # æ¸…é™¤ä»»åŠ¡çŠ¶æ€
        if filename in processing_tasks:
            del processing_tasks[filename]
        return {"message": f"å·²åˆ é™¤è¾“å‡ºæ–‡ä»¶: {output_path.name}"}
    else:
        raise HTTPException(status_code=404, detail="è¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨")


@app.get("/api/documents/{filename}/chunks")
async def get_document_chunks(filename: str):
    """è·å–æ–‡æ¡£çš„æ‰€æœ‰chunksï¼ˆä»æ•°æ®åº“ï¼‰"""
    # å…ˆæŸ¥æ‰¾æ–‡æ¡£
    doc = get_document_by_filename(filename)
    if not doc:
        raise HTTPException(status_code=404, detail="Document not found in database")

    # è·å–æ‰€æœ‰chunks
    from database import get_chunks_by_document
    chunks = get_chunks_by_document(doc['id'])

    return {
        "metadata": {
            "source_file": doc['filename'],
            "total_chunks": len(chunks),
            "document_id": doc['id']
        },
        "chunks": chunks
    }


@app.patch("/api/chunks/{chunk_id}")
async def update_chunk_endpoint(chunk_id: int, request: ChunkUpdateRequest):
    """æ›´æ–°chunkå†…å®¹å¹¶è®°å½•ç‰ˆæœ¬"""
    # è·å–æ—§æ•°æ®
    chunk = get_chunk(chunk_id)
    if not chunk:
        raise HTTPException(status_code=404, detail="Chunk not found")

    # ä¿å­˜æ—§å€¼ç”¨äºå¯¹æ¯”
    old_data = {
        "edited_content": chunk.get("edited_content") or chunk.get("content"),
        "status": chunk.get("status"),
        "content_tags": chunk.get("content_tags", []),
        "user_tag": chunk.get("user_tag")
    }

    # æ›´æ–°chunkï¼ˆè‡ªåŠ¨å¢åŠ ç‰ˆæœ¬å·ï¼‰
    update_chunk(
        chunk_id=chunk_id,
        edited_content=request.edited_content,
        status=request.status,
        content_tags=request.content_tags,
        user_tag=request.user_tag,
        last_editor_id=request.editor_id
    )

    # æ„å»ºå˜æ›´è®°å½•
    changes = {}
    if request.edited_content and request.edited_content != old_data["edited_content"]:
        changes["edited_content"] = {
            "before": old_data["edited_content"],
            "after": request.edited_content
        }

    if request.status is not None and request.status != old_data["status"]:
        status_names = {-1: "åºŸå¼ƒ", 0: "åˆå§‹", 1: "å·²ç¡®è®¤", 2: "å·²å‘é‡åŒ–"}
        changes["status"] = {
            "before": old_data["status"],
            "after": request.status,
            "before_name": status_names.get(old_data["status"], "æœªçŸ¥"),
            "after_name": status_names.get(request.status, "æœªçŸ¥")
        }

    if request.content_tags is not None and request.content_tags != old_data["content_tags"]:
        changes["content_tags"] = {
            "before": old_data["content_tags"],
            "after": request.content_tags
        }

    if request.user_tag and request.user_tag != old_data["user_tag"]:
        changes["user_tag"] = {
            "before": old_data["user_tag"],
            "after": request.user_tag
        }

    # è®°å½•æ—¥å¿—
    if changes:
        action = "status_change" if "status" in changes and len(changes) == 1 else "update"
        message = f"æ›´æ–°äº†chunk" if action == "update" else f"çŠ¶æ€å˜æ›´"

        insert_log(
            document_id=chunk["document_id"],
            chunk_id=chunk_id,
            action=action,
            message=message,
            user_id=request.editor_id,
            payload={"changes": changes, "timestamp": datetime.utcnow().isoformat()}
        )

    # è¿”å›æ›´æ–°åçš„chunk
    updated_chunk = get_chunk(chunk_id)
    return updated_chunk


@app.get("/api/chunks/{chunk_id}/logs", response_model=List[ChunkLogEntry])
async def get_chunk_logs_endpoint(chunk_id: int, limit: int = 50):
    """è·å–chunkçš„ç‰ˆæœ¬å†å²"""
    chunk = get_chunk(chunk_id)
    if not chunk:
        raise HTTPException(status_code=404, detail="Chunk not found")

    logs = get_chunk_logs(chunk_id, limit=limit)

    return [
        ChunkLogEntry(
            id=log["id"],
            action=log["action"],
            message=log["message"],
            created_at=log["created_at"],
            user_id=log["user_id"],
            payload=log["payload"]
        )
        for log in logs
    ]


# ============================================
# æ ‡ç­¾ç®¡ç† API
# ============================================

class TagRequest(BaseModel):
    """æ ‡ç­¾è¯·æ±‚"""
    tag_text: str


# ============================================
# å‘é‡åŒ– API Models
# ============================================

class VectorizeRequest(BaseModel):
    """å‘é‡åŒ–è¯·æ±‚"""
    chunk_ids: List[int]
    document_tags: Optional[List[str]] = None


class VectorizeResponse(BaseModel):
    """å‘é‡åŒ–å“åº”"""
    success_count: int
    failed_count: int
    skipped_count: int
    success_ids: List[int]
    failed_ids: List[int]
    skipped_ids: List[int]


class SearchRequest(BaseModel):
    """è¯­ä¹‰æœç´¢è¯·æ±‚"""
    query: str
    top_k: int = 5
    filters: Optional[Dict[str, Any]] = None


class SearchResult(BaseModel):
    """æœç´¢ç»“æœ"""
    chunk_id: int
    milvus_id: str
    content: str
    score: float
    metadata: Dict[str, Any]


@app.get("/api/documents/{filename}/tags")
async def get_document_tags_endpoint(filename: str):
    """è·å–æ–‡æ¡£çš„æ‰€æœ‰æ ‡ç­¾"""
    tags = get_tags_by_filename(filename)
    return {"filename": filename, "tags": tags}


@app.post("/api/documents/{filename}/tags")
async def add_document_tag_endpoint(filename: str, request: TagRequest):
    """æ·»åŠ æ–‡æ¡£æ ‡ç­¾"""
    success = add_tag_by_filename(filename, request.tag_text)
    if success:
        return {"message": "æ ‡ç­¾æ·»åŠ æˆåŠŸ", "tag": request.tag_text}
    else:
        raise HTTPException(status_code=400, detail="æ ‡ç­¾å·²å­˜åœ¨æˆ–æ–‡æ¡£ä¸å­˜åœ¨")


@app.delete("/api/documents/{filename}/tags/{tag_text}")
async def remove_document_tag_endpoint(filename: str, tag_text: str):
    """åˆ é™¤æ–‡æ¡£æ ‡ç­¾"""
    success = remove_tag_by_filename(filename, tag_text)
    if success:
        return {"message": "æ ‡ç­¾åˆ é™¤æˆåŠŸ", "tag": tag_text}
    else:
        raise HTTPException(status_code=404, detail="æ ‡ç­¾ä¸å­˜åœ¨æˆ–æ–‡æ¡£ä¸å­˜åœ¨")


# ============================================
# å‘é‡åŒ– API
# ============================================

@app.post("/api/chunks/vectorize/batch", response_model=VectorizeResponse)
async def vectorize_chunks_batch(request: VectorizeRequest):
    """æ‰¹é‡å‘é‡åŒ– chunks"""
    try:
        manager = get_vectorization_manager()

        # è·å–éœ€è¦å‘é‡åŒ–çš„ chunks
        chunks_to_vectorize = []
        for chunk_id in request.chunk_ids:
            chunk = get_chunk(chunk_id)
            if chunk:
                chunks_to_vectorize.append(chunk)

        if not chunks_to_vectorize:
            raise HTTPException(status_code=404, detail="æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„ chunks")

        # æ‰§è¡Œæ‰¹é‡å‘é‡åŒ–
        result = manager.vectorize_chunks(chunks_to_vectorize, request.document_tags)

        # è°ƒè¯•ï¼šæ‰“å°ç»“æœç»“æ„
        print(f"ğŸ” å‘é‡åŒ–ç»“æœ: success={len(result.get('success', []))}, failed={len(result.get('failed', []))}, skipped={len(result.get('skipped', []))}")
        if result.get('success'):
            print(f"   æˆåŠŸç¤ºä¾‹: {result['success'][0]}")
        if result.get('failed'):
            print(f"   å¤±è´¥ç¤ºä¾‹: {result['failed'][0]}")
        if result.get('skipped'):
            print(f"   è·³è¿‡ç¤ºä¾‹: {result['skipped'][0]}")

        # æ›´æ–°æ•°æ®åº“çŠ¶æ€
        for success_item in result.get('success', []):
            if success_item and 'chunk_id' in success_item and 'milvus_id' in success_item:
                update_chunk_milvus_id(success_item['chunk_id'], success_item['milvus_id'])

        return VectorizeResponse(
            success_count=len(result.get('success', [])),
            failed_count=len(result.get('failed', [])),
            skipped_count=len(result.get('skipped', [])),
            success_ids=[item.get('chunk_id') for item in result.get('success', []) if item and 'chunk_id' in item],
            failed_ids=[item.get('chunk_id') for item in result.get('failed', []) if item and 'chunk_id' in item],
            skipped_ids=[item.get('chunk_id') for item in result.get('skipped', []) if item and 'chunk_id' in item]
        )

    except Exception as e:
        import traceback
        error_detail = f"æ‰¹é‡å‘é‡åŒ–å¤±è´¥: {str(e)}\n{traceback.format_exc()}"
        print(error_detail)  # å¼ºåˆ¶æ‰“å°åˆ°æ§åˆ¶å°
        raise HTTPException(status_code=500, detail=f"æ‰¹é‡å‘é‡åŒ–å¤±è´¥: {str(e)}")


class SingleVectorizeRequest(BaseModel):
    """å•ä¸ªå‘é‡åŒ–è¯·æ±‚"""
    document_tags: Optional[List[str]] = None


@app.post("/api/chunks/{chunk_id}/vectorize")
async def vectorize_single_chunk(chunk_id: int, request: SingleVectorizeRequest = None):
    """å•ä¸ª chunk å‘é‡åŒ–"""
    try:
        chunk = get_chunk(chunk_id)
        if not chunk:
            raise HTTPException(status_code=404, detail="Chunk not found")

        # æ£€æŸ¥çŠ¶æ€
        if chunk.get('status') == -1:
            raise HTTPException(status_code=400, detail="åºŸå¼ƒçš„ chunk æ— æ³•å‘é‡åŒ–")

        if chunk.get('status') == 2:
            raise HTTPException(status_code=400, detail="è¯¥ chunk å·²ç»å‘é‡åŒ–")

        # è·å– document_tagsï¼ˆæ”¯æŒè¯·æ±‚ä½“ï¼‰
        document_tags = request.document_tags if request else None

        manager = get_vectorization_manager()
        result = manager.vectorize_chunks([chunk], document_tags)

        if result['success']:
            success_item = result['success'][0]
            update_chunk_milvus_id(success_item['chunk_id'], success_item['milvus_id'])

            # è®°å½•æ—¥å¿—
            insert_log(
                document_id=chunk['document_id'],
                chunk_id=chunk_id,
                action="vectorize",
                message="å‘é‡åŒ–æˆåŠŸ",
                user_id="system",
                payload={"milvus_id": success_item['milvus_id']}
            )

            return {"message": "å‘é‡åŒ–æˆåŠŸ", "milvus_id": success_item['milvus_id']}

        elif result['failed']:
            raise HTTPException(status_code=500, detail=result['failed'][0].get('error', 'å‘é‡åŒ–å¤±è´¥'))

        else:
            raise HTTPException(status_code=400, detail="Chunk è¢«è·³è¿‡")

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"å‘é‡åŒ–å¤±è´¥: {str(e)}")


@app.get("/api/vectorization/stats")
async def get_vectorization_stats_endpoint():
    """è·å–å‘é‡åŒ–ç»Ÿè®¡ä¿¡æ¯"""
    try:
        stats = get_vectorization_stats()
        return stats
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}")


@app.get("/api/chunks/vectorizable")
async def get_vectorizable_chunks_endpoint(limit: Optional[int] = None):
    """è·å–æ‰€æœ‰å¯å‘é‡åŒ–çš„ chunks"""
    try:
        chunks = get_vectorizable_chunks(limit=limit)
        return {"count": len(chunks), "chunks": chunks}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–å¯å‘é‡åŒ– chunks å¤±è´¥: {str(e)}")


@app.delete("/api/chunks/{chunk_id}/vectorize")
async def delete_chunk_from_vector(chunk_id: int):
    """ä»å‘é‡åº“åˆ é™¤ chunkï¼ˆåˆ é™¤è¯¥ chunk çš„æ‰€æœ‰å†å²å‘é‡ï¼‰"""
    try:
        chunk = get_chunk(chunk_id)
        if not chunk:
            raise HTTPException(status_code=404, detail="Chunk not found")

        # ä» Milvus åˆ é™¤è¯¥ chunk_db_id çš„æ‰€æœ‰å‘é‡ï¼ˆåŒ…æ‹¬å†å²å‘é‡ï¼‰
        manager = get_vectorization_manager()
        manager.vector_store.delete_by_chunk_db_ids([chunk_id])

        # æ›´æ–°æ•°æ®åº“çŠ¶æ€ï¼šæ¸…é™¤ milvus_idï¼ŒçŠ¶æ€æ”¹å› 0ï¼ˆåˆå§‹ï¼‰
        with get_connection() as conn:
            old_milvus_id = chunk.get('milvus_id')
            conn.execute("""
                UPDATE document_chunks
                SET milvus_id = NULL, status = 0
                WHERE id = ?
            """, (chunk_id,))
            conn.commit()

        # è®°å½•æ—¥å¿—
        insert_log(
            document_id=chunk['document_id'],
            chunk_id=chunk_id,
            action="delete_vector",
            message="ä»å‘é‡åº“åˆ é™¤ï¼ˆåŒ…æ‹¬æ‰€æœ‰å†å²å‘é‡ï¼‰",
            user_id="system",
            payload={"chunk_db_id": chunk_id, "old_milvus_id": old_milvus_id}
        )

        return {"message": "ä»å‘é‡åº“åˆ é™¤æˆåŠŸ", "chunk_db_id": chunk_id}

    except HTTPException:
        raise
    except Exception as e:
        import traceback
        error_detail = f"åˆ é™¤å¤±è´¥: {str(e)}\n{traceback.format_exc()}"
        print(error_detail)
        raise HTTPException(status_code=500, detail=f"åˆ é™¤å¤±è´¥: {str(e)}")


@app.get("/api/chunks/tags")
async def get_all_chunk_tags():
    """è·å–æ‰€æœ‰ chunk çš„æ ‡ç­¾ï¼ˆåŒ…æ‹¬ user_tag å’Œ content_tagsï¼‰"""
    try:
        with get_connection() as conn:
            # è·å–æ‰€æœ‰ user_tag
            user_tags = conn.execute("""
                SELECT DISTINCT user_tag
                FROM document_chunks
                WHERE user_tag IS NOT NULL AND user_tag != ''
            """).fetchall()

            # è·å–æ‰€æœ‰ content_tagsï¼ˆJSON æ•°ç»„ï¼‰
            content_tags_rows = conn.execute("""
                SELECT DISTINCT content_tags
                FROM document_chunks
                WHERE content_tags IS NOT NULL AND content_tags != '[]'
            """).fetchall()

        # åˆå¹¶æ‰€æœ‰æ ‡ç­¾
        all_tags = set()

        # æ·»åŠ  user_tags
        for row in user_tags:
            if row['user_tag']:
                all_tags.add(row['user_tag'])

        # è§£æ content_tags JSON
        import json
        for row in content_tags_rows:
            try:
                tags = json.loads(row['content_tags'])
                if isinstance(tags, list):
                    for tag in tags:
                        # ç§»é™¤ @ å‰ç¼€ï¼ˆäººå·¥æ ‡ç­¾ï¼‰
                        clean_tag = tag.lstrip('@') if isinstance(tag, str) else tag
                        if clean_tag:
                            all_tags.add(clean_tag)
            except:
                continue

        return {"tags": sorted(list(all_tags))}

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–æ ‡ç­¾å¤±è´¥: {str(e)}")


# ============================================
# å…¨å±€æ ‡ç­¾ç®¡ç† API
# ============================================

class TagStatsResponse(BaseModel):
    """æ ‡ç­¾ç»Ÿè®¡å“åº”"""
    name: str
    type: str  # user_tag | content_tag | both
    count: int
    chunk_ids: List[int]


class TagDeleteRequest(BaseModel):
    """æ ‡ç­¾åˆ é™¤è¯·æ±‚"""
    tag_name: str


class TagRenameRequest(BaseModel):
    """æ ‡ç­¾é‡å‘½åè¯·æ±‚"""
    old_name: str
    new_name: str


class TagMergeRequest(BaseModel):
    """æ ‡ç­¾åˆå¹¶è¯·æ±‚"""
    source_tags: List[str]
    target_tag: str


@app.get("/api/tags/all", response_model=List[TagStatsResponse])
async def get_all_tags_stats():
    """è·å–æ‰€æœ‰æ ‡ç­¾åŠç»Ÿè®¡ä¿¡æ¯"""
    try:
        tags = get_all_tags_with_stats()
        return tags
    except Exception as e:
        import traceback
        error_detail = f"è·å–æ ‡ç­¾ç»Ÿè®¡å¤±è´¥: {str(e)}\n{traceback.format_exc()}"
        print(error_detail)
        raise HTTPException(status_code=500, detail=f"è·å–æ ‡ç­¾ç»Ÿè®¡å¤±è´¥: {str(e)}")


@app.post("/api/tags/delete")
async def delete_tag(request: TagDeleteRequest):
    """åˆ é™¤æ ‡ç­¾ï¼ˆä»æ‰€æœ‰ chunks ä¸­åˆ é™¤ï¼‰"""
    try:
        tag_name = request.tag_name.strip()
        if not tag_name:
            raise HTTPException(status_code=400, detail="æ ‡ç­¾åç§°ä¸èƒ½ä¸ºç©º")

        # æ‰§è¡Œåˆ é™¤
        affected_count = delete_tag_from_all_chunks(tag_name)

        # è®°å½•æ—¥å¿—ï¼ˆå…¨å±€æ“ä½œï¼Œæ²¡æœ‰ç‰¹å®š document_idï¼‰
        # è¿™é‡Œæˆ‘ä»¬å¯ä»¥è®°å½•åˆ°ä¸€ä¸ªç‰¹æ®Šçš„æ–‡æ¡£æˆ–è€…è·³è¿‡
        # ä¸ºç®€åŒ–ï¼Œç›´æ¥è¿”å›ç»“æœ

        return {
            "affected_chunks": affected_count,
            "message": f"å·²ä» {affected_count} ä¸ªåˆ‡ç‰‡ä¸­åˆ é™¤æ ‡ç­¾ '{tag_name}'"
        }

    except HTTPException:
        raise
    except Exception as e:
        import traceback
        error_detail = f"åˆ é™¤æ ‡ç­¾å¤±è´¥: {str(e)}\n{traceback.format_exc()}"
        print(error_detail)
        raise HTTPException(status_code=500, detail=f"åˆ é™¤æ ‡ç­¾å¤±è´¥: {str(e)}")


@app.post("/api/tags/rename")
async def rename_tag(request: TagRenameRequest):
    """é‡å‘½åæ ‡ç­¾ï¼ˆåœ¨æ‰€æœ‰ chunks ä¸­ï¼‰"""
    try:
        old_name = request.old_name.strip()
        new_name = request.new_name.strip()

        if not old_name or not new_name:
            raise HTTPException(status_code=400, detail="æ ‡ç­¾åç§°ä¸èƒ½ä¸ºç©º")

        if old_name == new_name:
            raise HTTPException(status_code=400, detail="æ–°æ—§æ ‡ç­¾åç§°ç›¸åŒ")

        # æ‰§è¡Œé‡å‘½å
        affected_count = rename_tag_in_all_chunks(old_name, new_name)

        return {
            "affected_chunks": affected_count,
            "message": f"å·²å°† {affected_count} ä¸ªåˆ‡ç‰‡ä¸­çš„æ ‡ç­¾ '{old_name}' é‡å‘½åä¸º '{new_name}'"
        }

    except HTTPException:
        raise
    except Exception as e:
        import traceback
        error_detail = f"é‡å‘½åæ ‡ç­¾å¤±è´¥: {str(e)}\n{traceback.format_exc()}"
        print(error_detail)
        raise HTTPException(status_code=500, detail=f"é‡å‘½åæ ‡ç­¾å¤±è´¥: {str(e)}")


@app.post("/api/tags/merge")
async def merge_tags(request: TagMergeRequest):
    """åˆå¹¶æ ‡ç­¾ï¼ˆå°†å¤šä¸ªæ ‡ç­¾åˆå¹¶ä¸ºä¸€ä¸ªï¼‰"""
    try:
        source_tags = [tag.strip() for tag in request.source_tags if tag.strip()]
        target_tag = request.target_tag.strip()

        if not source_tags:
            raise HTTPException(status_code=400, detail="æºæ ‡ç­¾åˆ—è¡¨ä¸èƒ½ä¸ºç©º")

        if not target_tag:
            raise HTTPException(status_code=400, detail="ç›®æ ‡æ ‡ç­¾ä¸èƒ½ä¸ºç©º")

        if len(source_tags) < 2:
            raise HTTPException(status_code=400, detail="è‡³å°‘éœ€è¦ 2 ä¸ªæºæ ‡ç­¾æ‰èƒ½åˆå¹¶")

        # æ‰§è¡Œåˆå¹¶
        result = merge_tags_in_all_chunks(source_tags, target_tag)

        return {
            "affected_chunks": result['affected_chunks'],
            "merged_count": result['merged_count'],
            "message": f"å·²å°† {result['merged_count']} ä¸ªæ ‡ç­¾åˆå¹¶ä¸º '{target_tag}'ï¼Œå½±å“ {result['affected_chunks']} ä¸ªåˆ‡ç‰‡"
        }

    except HTTPException:
        raise
    except Exception as e:
        import traceback
        error_detail = f"åˆå¹¶æ ‡ç­¾å¤±è´¥: {str(e)}\n{traceback.format_exc()}"
        print(error_detail)
        raise HTTPException(status_code=500, detail=f"åˆå¹¶æ ‡ç­¾å¤±è´¥: {str(e)}")


@app.post("/api/chunks/search", response_model=List[SearchResult])
async def search_chunks(request: SearchRequest):
    """è¯­ä¹‰æœç´¢ chunks"""
    try:
        manager = get_vectorization_manager()
        results = manager.search_chunks(
            query=request.query,
            k=request.top_k,
            filters=request.filters,
            with_score=True
        )

        # è½¬æ¢ä¸ºå“åº”æ ¼å¼
        search_results = []
        for result in results:
            # ä» metadata è·å– chunk_db_id
            metadata = result.get('metadata', {})
            chunk_db_id = metadata.get('chunk_db_id')

            if chunk_db_id:
                # Milvus æœç´¢ç»“æœå¿…ç„¶æœ‰ pkï¼ˆä¸»é”®ï¼‰ï¼Œå°±æ˜¯ milvus_id
                milvus_id = str(metadata.get('pk', ''))

                if not milvus_id:
                    # å¦‚æœæ²¡æœ‰ pkï¼Œä»æ•°æ®åº“è·å–ï¼ˆç†è®ºä¸Šä¸åº”è¯¥å‘ç”Ÿï¼‰
                    chunk = get_chunk(chunk_db_id)
                    if chunk and chunk.get('milvus_id'):
                        milvus_id = chunk['milvus_id']
                    else:
                        continue  # è·³è¿‡æ²¡æœ‰ milvus_id çš„ç»“æœ

                search_results.append(SearchResult(
                    chunk_id=chunk_db_id,
                    milvus_id=milvus_id,
                    content=result.get('content', ''),
                    score=result.get('score', 0.0),
                    metadata=metadata
                ))

        return search_results

    except Exception as e:
        import traceback
        error_detail = f"æœç´¢å¤±è´¥: {str(e)}\n{traceback.format_exc()}"
        print(error_detail)
        raise HTTPException(status_code=500, detail=f"æœç´¢å¤±è´¥: {str(e)}")


@app.get("/")
async def root():
    """APIæ ¹è·¯å¾„"""
    return {
        "message": "RAG Preprocessor API",
        "version": "1.0.0",
        "endpoints": {
            "documents": "/api/documents",
            "document_status": "/api/documents/{filename}/status",
            "document_chunks": "/api/documents/{filename}/chunks",
            "document_tags": "/api/documents/{filename}/tags",
            "add_tag": "POST /api/documents/{filename}/tags",
            "remove_tag": "DELETE /api/documents/{filename}/tags/{tag_text}",
            "process": "/api/documents/{filename}/process",
            "delete_output": "/api/documents/{filename}/output",
            "update_chunk": "/api/chunks/{chunk_id}",
            "chunk_logs": "/api/chunks/{chunk_id}/logs",
            "vectorize_batch": "POST /api/chunks/vectorize/batch",
            "vectorize_single": "POST /api/chunks/{chunk_id}/vectorize",
            "vectorization_stats": "GET /api/vectorization/stats",
            "vectorizable_chunks": "GET /api/chunks/vectorizable",
            "search": "POST /api/chunks/search"
        }
    }


if __name__ == "__main__":
    # åˆå§‹åŒ–æ•°æ®åº“
    try:
        init_database()
    except Exception as e:
        print(f"Warning: Database initialization failed: {e}")

    uvicorn.run(
        "api_server:app",
        host="0.0.0.0",
        port=8000,
        reload=True
    )
