"""
Agent å¯¹è¯è·¯ç”±
æä¾› Agent Reactã€å·¥å…·åˆ—è¡¨ã€åŠ©æ‰‹åˆ—è¡¨ç­‰åŠŸèƒ½
"""

import json
import asyncio
import os
from typing import List, Dict, Any
from fastapi import APIRouter
from pydantic import BaseModel
from starlette.responses import StreamingResponse
from loguru import logger
from urllib.parse import quote

router = APIRouter()


# ==================== Pydantic Models ====================

class AgentReactRequest(BaseModel):
    """Agent React è¯·æ±‚"""
    messages: List[Dict[str, Any]]
    stream: bool = True


# ==================== API ====================

@router.get("/api/assistants")
async def get_assistants():
    """è·å–åŠ©æ‰‹åˆ—è¡¨"""
    assistants = [
        {
            "id": "rag-assistant",
            "name": "RAGçŸ¥è¯†åŠ©æ‰‹",
            "description": "åŸºäºæ–‡æ¡£çš„æ™ºèƒ½é—®ç­”åŠ©æ‰‹",
            "model": "dspy-rag",
            "capabilities": ["document_qa", "semantic_search", "clarification"],
            "status": "1",  # 1 è¡¨ç¤ºæ¿€æ´»çŠ¶æ€
            "use-type": ["knowledge", "base", "semantic_search"]
        }
    ]

    return {
        "success": True,
        "data": {
            "assistants": assistants,
            "active": assistants[0]  # é»˜è®¤ç¬¬ä¸€ä¸ªä¸ºæ´»è·ƒåŠ©æ‰‹
        },
        "message": "è·å–åŠ©æ‰‹ä¿¡æ¯æˆåŠŸ"
    }


@router.get("/api/agent/tools")
async def get_agent_tools():
    """è·å–å¯ç”¨å·¥å…·åˆ—è¡¨"""
    return {
        "tools": [
            {
                "name": "document_search",
                "description": "æœç´¢æ–‡æ¡£å†…å®¹",
                "status": "active",
                "type": "retrieval"
            },
            {
                "name": "semantic_search",
                "description": "è¯­ä¹‰ç›¸ä¼¼åº¦æœç´¢",
                "status": "active",
                "type": "retrieval"
            },
            {
                "name": "tag_filter",
                "description": "æ ‡ç­¾è¿‡æ»¤",
                "status": "active",
                "type": "filter"
            }
        ]
    }


@router.post("/api/agent/react")
async def agent_react(request: AgentReactRequest):
    """Agent React æ¥å£ï¼ˆSSE æµå¼å“åº”ï¼‰- çœŸæ­£è°ƒç”¨ DSPy RAG"""
    from chat_routes import get_dspy_pipeline, get_conversation_manager

    def extract_text_content(content) -> str:
        """æå–æ¶ˆæ¯å†…å®¹æ–‡æœ¬ï¼ˆæ”¯æŒå­—ç¬¦ä¸²æˆ–æ•°ç»„æ ¼å¼ï¼‰"""
        if isinstance(content, str):
            return content
        elif isinstance(content, list):
            texts = []
            for item in content:
                if isinstance(item, dict):
                    if item.get('type') == 'text' and 'text' in item:
                        texts.append(item['text'])
                    elif 'text' in item:
                        texts.append(str(item['text']))
            return ' '.join(texts)
        return str(content)

    async def event_stream():
        """ç”Ÿæˆ SSE äº‹ä»¶æµ"""
        try:
            # æå–æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯
            user_messages = [msg for msg in request.messages if msg.get('role') == 'user']
            if not user_messages:
                yield f'data: {json.dumps({"type": "error", "content": "No user message found"})}\n\n'
                return

            last_message = user_messages[-1]
            query = extract_text_content(last_message.get('content', ''))

            logger.info(f"---- query extracted ---  : {query}")

            # === Phase 1: åˆå§‹åŒ–å’Œæ„å›¾è¯†åˆ« ===
            yield f'data: {json.dumps({"type": "reasoning", "content": "å¼€å§‹åˆ†æé—®é¢˜..."})}\n\n'
            await asyncio.sleep(0.05)

            # å·¥å…·çŠ¶æ€ï¼šæ¿€æ´»æ„å›¾è¯†åˆ«å·¥å…·
            status_data = {"toolName": "intent_classifier", "status": "active"}
            canvas_content = {"canvas-type": "status", "canvas-source": status_data}
            yield f'data: {json.dumps({"type": "canvas", "content": canvas_content})}\n\n'
            await asyncio.sleep(0.05)

            # è·å– DSPy Pipeline å’Œå¯¹è¯ç®¡ç†å™¨
            try:
                pipeline = get_dspy_pipeline()
                conv_manager = get_conversation_manager()
            except Exception as e:
                yield f'data: {json.dumps({"type": "error", "content": f"åˆå§‹åŒ–å¤±è´¥: {str(e)}"})}\n\n'
                return

            # æ„å»ºå¯¹è¯å†å²
            history_messages = []
            for msg in request.messages[:-1]:
                role = msg.get('role', '')
                content = extract_text_content(msg.get('content', ''))
                if role in ['user', 'assistant'] and content:
                    history_messages.append(f"{role}: {content}")
            history = "\n".join(history_messages) if history_messages else ""

            # è°ƒç”¨ DSPy Pipeline å¤„ç†ï¼ˆå…ˆå®Œæˆæ„å›¾è¯†åˆ«ï¼‰
            result = pipeline.process_query(query, history)

            # å…³é—­æ„å›¾è¯†åˆ«å·¥å…·çŠ¶æ€
            status_data = {"toolName": "intent_classifier", "status": "inactive"}
            canvas_content = {"canvas-type": "status", "canvas-source": status_data}
            yield f'data: {json.dumps({"type": "canvas", "content": canvas_content})}\n\n'

            # === Phase 2: æ„å›¾è¯†åˆ«ç»“æœ ===
            intent_info = result.get('intent')
            if intent_info:
                # å¤„ç† intent å¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–å­—å…¸çš„æƒ…å†µ
                if isinstance(intent_info, dict):
                    intent_type = intent_info.get('intent', 'æœªçŸ¥')
                    confidence = intent_info.get('confidence', 0)
                    reasoning = intent_info.get('reasoning', '')

                    # æ„å›¾ç±»å‹æ˜ å°„
                    intent_map = {
                        'question': 'é—®ç­”è¯·æ±‚',
                        'chitchat': 'ğŸ’¬ é—²èŠ',
                        'clarification': 'ğŸ¤” éœ€è¦æ¾„æ¸…',
                        'unknown': 'æœªçŸ¥æ„å›¾'
                    }
                    intent_display = intent_map.get(intent_type, f'ğŸ” {intent_type}')

                    intent_text = f"è¯†åˆ«æ„å›¾: {intent_display}"
                    if confidence > 0:
                        intent_text += f" (ç½®ä¿¡åº¦: {confidence*100:.0f}%)"

                    yield f'data: {json.dumps({"type": "reasoning", "content": intent_text})}\n\n'
                    await asyncio.sleep(0.05)

                    # å¦‚æœæœ‰æ¨ç†è¯´æ˜ï¼Œä¹Ÿæ˜¾ç¤ºå‡ºæ¥ï¼ˆç®€çŸ­ç‰ˆæœ¬ï¼‰
                    if reasoning and len(reasoning) <= 100:
                        reasoning_text = f"ğŸ’­ {reasoning}"
                        yield f'data: {json.dumps({"type": "reasoning", "content": reasoning_text})}\n\n'
                        await asyncio.sleep(0.05)
                else:
                    # å¦‚æœæ˜¯ç®€å•å­—ç¬¦ä¸²
                    intent_text = f"è¯†åˆ«æ„å›¾: {intent_info}"
                    confidence = result.get('confidence', 0)
                    if confidence > 0:
                        intent_text += f" (ç½®ä¿¡åº¦: {confidence*100:.0f}%)"
                    yield f'data: {json.dumps({"type": "reasoning", "content": intent_text})}\n\n'
                    await asyncio.sleep(0.05)

            # === Phase 3: æ–‡æ¡£æ£€ç´¢ï¼ˆä»…å½“éœ€è¦æ—¶ï¼‰===
            sources = result.get('sources', [])
            result_type = result.get('type', 'answer')

            # åªæœ‰åœ¨éœ€è¦æ–‡æ¡£æ£€ç´¢çš„æƒ…å†µä¸‹æ‰æ˜¾ç¤ºæ£€ç´¢è¿‡ç¨‹
            if sources or result_type in ['answer', 'clarification']:
                yield f'data: {json.dumps({"type": "reasoning", "content": "ğŸ” å¼€å§‹æ£€ç´¢ç›¸å…³æ–‡æ¡£..."})}\n\n'
                await asyncio.sleep(0.05)

                # å·¥å…·çŠ¶æ€ï¼šæ¿€æ´»æ–‡æ¡£æœç´¢
                status_data = {"toolName": "document_search", "status": "active"}
                canvas_content = {"canvas-type": "status", "canvas-source": status_data}
                yield f'data: {json.dumps({"type": "canvas", "content": canvas_content})}\n\n'
                await asyncio.sleep(0.05)

            # === Phase 4: æ£€ç´¢ç»“æœå±•ç¤º ===
            if sources:
                yield f'data: {json.dumps({"type": "reasoning", "content": f"æ‰¾åˆ° {len(sources)} ä¸ªç›¸å…³æ–‡æ¡£ç‰‡æ®µ"})}\n\n'
                await asyncio.sleep(0.05)

                # å‘é€æ–‡ä»¶æºä¿¡æ¯ï¼ˆä½¿ç”¨ files ç±»å‹ï¼‰
                api_base_url = os.getenv("API_BASE_URL", "http://localhost:8086")

                for i, source in enumerate(sources[:5]):  # æœ€å¤šæ˜¾ç¤º5ä¸ªæ¥æº
                    doc_name = source.get('document', f'æ–‡æ¡£{i+1}')
                    chunk_db_id = source.get('chunk_db_id', '')  # ä½¿ç”¨æ•°æ®åº“ä¸»é”®ID

                    # æ„é€ APIå¯¼èˆªURLï¼ˆæŒ‡å‘åç«¯APIï¼Œç”±åç«¯é‡å®šå‘åˆ°å‰ç«¯ï¼‰
                    if chunk_db_id and doc_name:
                        # URLç¼–ç æ–‡æ¡£åä»¥å¤„ç†ç‰¹æ®Šå­—ç¬¦
                        encoded_doc_name = quote(doc_name)
                        file_url = f"{api_base_url}/api/view/document/{encoded_doc_name}/chunk/{chunk_db_id}"
                    else:
                        # é™çº§ï¼šæ²¡æœ‰chunk_db_idæ—¶ä½¿ç”¨ä¼ ç»Ÿè·¯å¾„
                        file_url = source.get('file_path', f'/docs/{doc_name}')

                    files_content = {
                        "fileName": doc_name,
                        "filePath": file_url,
                        "chunkDbId": chunk_db_id,  # ä¼ é€’æ•°æ®åº“ä¸»é”®ID
                        "sourceFile": doc_name  # ä¼ é€’æºæ–‡ä»¶å
                    }
                    yield f'data: {json.dumps({"type": "files", "content": files_content})}\n\n'
                    await asyncio.sleep(0.05)

                # ä½¿ç”¨ canvas å±•ç¤ºè¯¦ç»†çš„æ£€ç´¢ç»“æœï¼ˆmarkdown æ ¼å¼ï¼‰
                sources_markdown_parts = ["## æ£€ç´¢åˆ°çš„å‚è€ƒæ–‡æ¡£\n"]
                for i, s in enumerate(sources[:3]):  # è¯¦ç»†æ˜¾ç¤ºå‰3ä¸ª
                    score = s.get('score', 0)
                    doc_name = s.get('document', 'Unknown')
                    content_preview = s.get('content', '')[:150]

                    sources_markdown_parts.append(f"### ğŸ“„ æ¥æº {i+1}: {doc_name}\n")
                    sources_markdown_parts.append(f"**ç›¸ä¼¼åº¦**: {score*100:.1f}%\n\n")
                    sources_markdown_parts.append(f"**å†…å®¹é¢„è§ˆ**:\n{content_preview}...\n")

                sources_markdown = "\n".join(sources_markdown_parts)
                canvas_content = {"canvas-type": "markdown", "canvas-source": sources_markdown}
                yield f'data: {json.dumps({"type": "canvas", "content": canvas_content})}\n\n'
                await asyncio.sleep(0.05)

            # å…³é—­æ–‡æ¡£æœç´¢å·¥å…·çŠ¶æ€ï¼ˆå¦‚æœæ‰“å¼€äº†ï¼‰
            if sources or result_type in ['answer', 'clarification']:
                status_data = {"toolName": "document_search", "status": "inactive"}
                canvas_content = {"canvas-type": "status", "canvas-source": status_data}
                yield f'data: {json.dumps({"type": "canvas", "content": canvas_content})}\n\n'

            # === Phase 5: ç”Ÿæˆå›ç­” ===
            # æ ¹æ®ä¸åŒç±»å‹æ˜¾ç¤ºä¸åŒçš„ç”Ÿæˆæç¤º
            if result_type == 'chitchat':
                yield f'data: {json.dumps({"type": "reasoning", "content": "ğŸ’¬ ç”Ÿæˆå›å¤..."})}\n\n'
                await asyncio.sleep(0.05)
            elif sources:
                yield f'data: {json.dumps({"type": "reasoning", "content": "ğŸ’¡ åŸºäºæ£€ç´¢ç»“æœç”Ÿæˆå›ç­”..."})}\n\n'
                await asyncio.sleep(0.05)

                # å·¥å…·çŠ¶æ€ï¼šæ¿€æ´»è¯­ä¹‰æœç´¢
                status_data = {"toolName": "semantic_search", "status": "active"}
                canvas_content = {"canvas-type": "status", "canvas-source": status_data}
                yield f'data: {json.dumps({"type": "canvas", "content": canvas_content})}\n\n'
                await asyncio.sleep(0.05)
            else:
                yield f'data: {json.dumps({"type": "reasoning", "content": "ğŸ’¡ ç”Ÿæˆå›ç­”..."})}\n\n'
                await asyncio.sleep(0.05)

            # === Phase 6: å‘é€æ­£å¼å›å¤ï¼ˆæµå¼ï¼‰ ===
            result_type = result.get('type', 'answer')
            response_text = ""

            if result_type == 'clarification':
                # éœ€è¦æ¾„æ¸…çš„æƒ…å†µ
                response_text = result.get('question', 'æŠ±æ­‰ï¼Œæˆ‘éœ€è¦æ›´å¤šä¿¡æ¯ã€‚')
                yield f'data: {json.dumps({"type": "content", "content": response_text})}\n\n'
                await asyncio.sleep(0.05)

                if result.get('options'):
                    choice_text = "\n\nè¯·é€‰æ‹©ï¼š"
                    yield f'data: {json.dumps({"type": "content", "content": choice_text})}\n\n'
                    await asyncio.sleep(0.05)
                    for i, opt in enumerate(result['options']):
                        option_text = f"\n{i+1}. {opt}"
                        yield f'data: {json.dumps({"type": "content", "content": option_text})}\n\n'
                        await asyncio.sleep(0.05)

            elif result_type == 'chitchat':
                response_text = result.get('response', 'æ‚¨å¥½ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®æ‚¨çš„å—ï¼Ÿ')
                # åˆ†æ®µå‘é€ï¼ˆæ¨¡æ‹Ÿæµå¼ï¼‰
                for chunk in [response_text[i:i+50] for i in range(0, len(response_text), 50)]:
                    yield f'data: {json.dumps({"type": "content", "content": chunk})}\n\n'
                    await asyncio.sleep(0.05)

            elif result_type == 'no_results':
                response_text = result.get('response', 'æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰æ‰¾åˆ°ç›¸å…³çš„æ–‡æ¡£å†…å®¹ã€‚')
                yield f'data: {json.dumps({"type": "content", "content": response_text})}\n\n'
                await asyncio.sleep(0.05)

                # æä¾›å»ºè®®
                suggestions = [
                    "\n\næ‚¨å¯ä»¥å°è¯•ï¼š",
                    "\n1. æ¢ä¸€ç§è¡¨è¿°æ–¹å¼",
                    "\n2. ä½¿ç”¨æ›´å…·ä½“çš„å…³é”®è¯",
                    "\n3. æŸ¥çœ‹å¯ç”¨çš„æ–‡æ¡£åˆ—è¡¨"
                ]
                for suggestion in suggestions:
                    yield f'data: {json.dumps({"type": "content", "content": suggestion})}\n\n'
                    await asyncio.sleep(0.05)

            else:  # answer type - æ ‡å‡†å›ç­”
                response_text = result.get('response', 'æŠ±æ­‰ï¼Œæ— æ³•ç”Ÿæˆå›ç­”ã€‚')

                # æµå¼åˆ†æ®µå‘é€ï¼ˆæŒ‰å¥å­æˆ–æ¢è¡Œç¬¦åˆ†å‰²ï¼‰
                sentences = response_text.split('\n')
                for i, sentence in enumerate(sentences):
                    if sentence.strip():
                        prefix = "" if i == 0 else "\n"
                        content = prefix + sentence
                        yield f'data: {json.dumps({"type": "content", "content": content})}\n\n'
                        await asyncio.sleep(0.05)

            # å…³é—­è¯­ä¹‰æœç´¢å·¥å…·çŠ¶æ€ï¼ˆå¦‚æœæ‰“å¼€äº†ï¼‰
            if sources:
                status_data = {"toolName": "semantic_search", "status": "inactive"}
                canvas_content = {"canvas-type": "status", "canvas-source": status_data}
                yield f'data: {json.dumps({"type": "canvas", "content": canvas_content})}\n\n'

            # === Phase 7: é™„åŠ ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰===
            # å¦‚æœæœ‰ç½®ä¿¡åº¦ä½çš„æƒ…å†µï¼Œæä¾›è­¦å‘Š
            if result.get('confidence', 1.0) < 0.5:
                warning_text = "âš ï¸ æç¤ºï¼šå›ç­”çš„ç½®ä¿¡åº¦è¾ƒä½ï¼Œå»ºè®®äººå·¥æ ¸å®"
                yield f'data: {json.dumps({"type": "reasoning", "content": warning_text})}\n\n'
                await asyncio.sleep(0.05)

            # å¦‚æœéœ€è¦ï¼Œå¯ä»¥æ·»åŠ ç»Ÿè®¡å›¾è¡¨
            if sources and len(sources) > 1:
                # åˆ›å»ºä¸€ä¸ªç®€å•çš„æ¥æºç»Ÿè®¡ HTML è¡¨æ ¼
                stats_html = "<div style='padding: 10px; background: #f5f5f5; border-radius: 5px;'>"
                stats_html += "<h4 style='margin-top: 0;'>ğŸ“Š æ£€ç´¢ç»Ÿè®¡</h4>"
                stats_html += f"<p><strong>æ£€ç´¢åˆ°çš„æ–‡æ¡£æ•°é‡ï¼š</strong> {len(sources)}</p>"
                if sources:
                    avg_score = sum(s.get('score', 0) for s in sources) / len(sources)
                    stats_html += f"<p><strong>å¹³å‡ç›¸ä¼¼åº¦ï¼š</strong> {avg_score*100:.1f}%</p>"
                stats_html += "</div>"

                canvas_content = {"canvas-type": "html", "canvas-source": stats_html}
                yield f'data: {json.dumps({"type": "canvas", "content": canvas_content})}\n\n'
                await asyncio.sleep(0.05)

            # === Phase 8: å®Œæˆæ ‡è®° ===
            yield f'data: {json.dumps({"type": "done"})}\n\n'

        except Exception as e:
            import traceback
            error_detail = f"{str(e)}\n{traceback.format_exc()}"
            print(f"Agent react error: {error_detail}")

            # å‘é€é”™è¯¯æ¶ˆæ¯
            error_msg = f"âŒ å¤„ç†è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
            yield f'data: {json.dumps({"type": "reasoning", "content": error_msg})}\n\n'
            error_content = "æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶é‡åˆ°äº†é—®é¢˜ã€‚è¯·ç¨åå†è¯•ã€‚"
            yield f'data: {json.dumps({"type": "content", "content": error_content})}\n\n'
            yield f'data: {json.dumps({"type": "done"})}\n\n'

    return StreamingResponse(
        event_stream(),
        media_type="text/event-stream; charset=utf-8",
        headers={
            "Cache-Control": "no-cache, no-transform",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",
            "Content-Type": "text/event-stream; charset=utf-8",
            "Transfer-Encoding": "chunked"
        }
    )
