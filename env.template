# ==================== RAG 文档预处理系统环境配置模板 ====================
# 使用说明：
# 1. 复制此文件为 .env：cp env.template .env
# 2. 填写必要的配置项（特别是 API 密钥）
# 3. 根据实际情况调整路径和参数

# ==================== 路径配置 ====================
# 基础目录：项目根目录
# 默认：当前项目的父目录的父目录
# BASE_DIR=/path/to/rag_preprocessor

# Markdown 文档目录：存放所有待处理的 .md 文件
# 默认：${BASE_DIR}/all-md
# ALL_MD_DIR=/path/to/all-md

# 输出目录：存放处理后的 JSON 文件
# 默认：${BASE_DIR}/rag-visualizer/public/output
# OUTPUT_DIR=/path/to/output

# 项目工作目录：当前项目目录（hit-rag/hit-rag）
# 默认：当前文件所在目录
# IKN_PLUS_DIR=/path/to/hit-rag

# ==================== LLM API 配置 ====================
# LLM 提供商选择：'azure' 或 'openai'
LLM_PROVIDER=azure

# Azure OpenAI 配置
AZURE_OPENAI_API_KEY=your_azure_api_key_here
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_API_VERSION=2024-02-15-preview
AZURE_OPENAI_DEPLOYMENT=gpt-4

# OpenAI 配置（可选）
# OPENAI_API_KEY=your_openai_api_key_here
# OPENAI_MODEL=gpt-4-turbo-preview

# API 调用参数
LLM_TEMPERATURE=0.1
LLM_MAX_TOKENS=4000
LLM_TIMEOUT=120
LLM_MAX_RETRIES=3
LLM_RETRY_DELAY=2

# ==================== Tokenizer 配置 ====================
# Tokenizer 类型
TOKENIZER_TYPE=tiktoken

# tiktoken 编码名称（必须与 LLM 模型匹配）
# GPT-4/GPT-3.5: "cl100k_base"
TOKENIZER_ENCODING_NAME=cl100k_base

# tiktoken 版本锁定
TOKENIZER_VERSION=0.5.2

# ==================== Token 切分参数 ====================
# 阶段1：粗切参数
MID_CHUNK_MAX_CHARS=1536
MID_CHUNK_OVERLAP_CHARS=100

# 阶段3：最终切分 Token 限制
FINAL_MIN_TOKENS=300
FINAL_TARGET_TOKENS=800
FINAL_MAX_TOKENS=2000
FINAL_HARD_LIMIT=3000

# ATOMIC 块特殊处理
ATOMIC_MAX_TOKENS=4000

# 语义完整性优先
SEMANTIC_INTEGRITY_PRIORITY=true

# 小 chunk 合并配置
ENABLE_SMALL_CHUNK_MERGE=true
SMALL_CHUNK_THRESHOLD=100

# Markdown 结构保持
PRESERVE_MARKDOWN_STRUCTURE=true

# ==================== 标签配置 ====================
# 内容推理标签数量
CONTENT_TAG_COUNT=5

# 标签推理语言
TAG_LANGUAGE=中文

# ==================== 日志配置 ====================
# 日志级别：DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

# 日志文件路径
LOG_FILE=logs/rag_preprocessor.log

# 详细日志记录选项
LOG_TOKEN_DETAILS=true
LOG_LLM_REQUESTS=true

# ==================== 输出配置 ====================
# 输出目录（已在路径配置中定义）
# OUTPUT_DIR=./output

# 中间结果保存（用于调试）
SAVE_INTERMEDIATE_RESULTS=true

# JSON 格式化缩进
JSON_INDENT=2

# ==================== 性能优化配置 ====================
# 批量处理大小
BATCH_SIZE=5

# 异步处理
ENABLE_ASYNC=true
MAX_CONCURRENT_REQUESTS=3

# 缓存配置
ENABLE_CACHE=true
CACHE_TTL=3600

# ==================== 验证配置 ====================
# Token 溢出检查
CHECK_TOKEN_OVERFLOW=true
STRICT_MODE=false

# Token 连续性检查
CHECK_TOKEN_CONTINUITY=true
TOKEN_GAP_THRESHOLD=50

# 完整性检查
CHECK_SENTENCE_INTEGRITY=true
CHECK_TABLE_INTEGRITY=true
CHECK_CODE_BLOCK_INTEGRITY=true

# ==================== 向量化配置 ====================
# Milvus 连接配置
MILVUS_HOST=127.0.0.1
MILVUS_PORT=19530
MILVUS_COLLECTION_NAME=knowledge

# Embedding 提供商：ollama | azure | openai
EMBEDDING_PROVIDER=ollama

# Ollama 配置
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_EMBEDDING_MODEL=qwen3-embedding:latest

# Azure OpenAI Embedding 配置
# AZURE_OPENAI_EMBEDDING_DEPLOYMENT=text-embedding-ada-002

# 批处理配置
VECTOR_BATCH_SIZE=20
VECTOR_MAX_RETRIES=3
VECTOR_RETRY_DELAY=2

# 索引配置
MILVUS_INDEX_TYPE=HNSW
MILVUS_METRIC_TYPE=L2

# HNSW 索引参数
MILVUS_HNSW_M=16
MILVUS_HNSW_EF_CONSTRUCTION=200

# 搜索配置
VECTOR_DEFAULT_TOP_K=5
MILVUS_SEARCH_EF=64

# 向量化策略
VECTOR_AUTO_VECTORIZE=false
VECTOR_SKIP_DEPRECATED=true
VECTOR_SKIP_VECTORIZED=true

